{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.feature_selection import RFE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time # For time complexity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data of HIGGS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\M'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\M'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18880\\1546570097.py:2: SyntaxWarning: invalid escape sequence '\\M'\n",
      "  file_path = \"E:\\ML\\HIGGS.csv\\HIGGS.csv\"\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "file_path = \"E:\\ML\\HIGGS.csv\\HIGGS.csv\"\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Sample 5% of the dataset\n",
    "df_sample = df.sample(frac=0.01, random_state=39)\n",
    "# print(df_sample.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: (110000, 28)\n",
      "New number of features with polynomial features: (110000, 406)\n",
      "Cross-Validation Results (Linear SVM):\n",
      "Accuracy: 0.6351038961038962\n",
      "Precision: 0.6182215449337651\n",
      "Recall: 0.8035944788491746\n",
      "F1 Score: 0.6988199165461573\n",
      "Area_ROC: 0.6736944022470748\n",
      "\n",
      "Test Set Evaluation (Linear SVM):\n",
      "Accuracy: 0.6358484848484849\n",
      "Precision: 0.6193308550185873\n",
      "Recall: 0.8104040288428522\n",
      "F1 Score: 0.702099705000124\n",
      "AUC: 0.6248980082382495\n",
      "Linear SVM Training Time: 297.96 seconds\n",
      "Linear SVM Prediction Time: 32.35 seconds\n"
     ]
    }
   ],
   "source": [
    "# Analyzing the data\n",
    "\n",
    "# Check for any missing values\n",
    "# print(\"\\nMissing values in each column:\\n\", df_sample.isnull().sum()\n",
    "\n",
    "# Assuming the first column as target column\n",
    "X = df_sample.drop(columns=[0])\n",
    "y = df_sample[0]\n",
    "\n",
    "# Data Preprocessing and Feature Selection\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply polynomial feature generation\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_scaled)\n",
    "\n",
    "# Check the shape to see the new number of features\n",
    "print(\"Original number of features:\", X_scaled.shape)\n",
    "print(\"New number of features with polynomial features:\", X_poly.shape)\n",
    "\n",
    "# Feature Selection: SelectKBest to reduce dimensionality\n",
    "select_k = SelectKBest(f_classif, k=10) \n",
    "X_selected = select_k.fit_transform(X_scaled, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=39)\n",
    "\n",
    "# 2. Linear SVM Implementation\n",
    "linear_svm = SVC(kernel='linear', random_state=39)\n",
    "\n",
    "# Cross-validation on training data\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "cv = cross_validate(linear_svm, X_train, y_train, cv=5, scoring=scoring)\n",
    "print(\"Cross-Validation Results (Linear SVM):\")\n",
    "print(\"Accuracy:\", np.mean(cv['test_accuracy']))\n",
    "print(\"Precision:\", np.mean(cv['test_precision']))\n",
    "print(\"Recall:\", np.mean(cv['test_recall']))\n",
    "print(\"F1 Score:\", np.mean(cv['test_f1']))\n",
    "print(\"Area_ROC:\", np.mean(cv['test_roc_auc']))\n",
    "\n",
    "# Fitting and Cross-validation on testing data\n",
    "start_time = time.time()\n",
    "linear_svm.fit(X_train, y_train)\n",
    "train_time_linear = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "y_predict_linear = linear_svm.predict(X_test)\n",
    "predict_time_linear = time.time() - start_time\n",
    "\n",
    "# Evaluation on test set\n",
    "print(\"\\nTest Set Evaluation (Linear SVM):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predict_linear))\n",
    "print(\"Precision:\", precision_score(y_test, y_predict_linear))\n",
    "print(\"Recall:\", recall_score(y_test, y_predict_linear))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_predict_linear))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_predict_linear))\n",
    "\n",
    "print(f\"Linear SVM Training Time: {train_time_linear:.2f} seconds\")\n",
    "print(f\"Linear SVM Prediction Time: {predict_time_linear:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Stochastic Gradeient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Results (SGDClassifier):\n",
      "Accuracy: 0.6305454545454545\n",
      "Precision: 0.6237754671295578\n",
      "Recall: 0.7544368457033552\n",
      "F1 Score: 0.6824685529530137\n",
      "Area under ROC: 0.6677014500057961\n",
      "\n",
      "Test Set Evaluation (SGDClassifier):\n",
      "Accuracy: 0.6339393939393939\n",
      "Precision: 0.6136823469903895\n",
      "Recall: 0.8331807256495365\n",
      "F1 Score: 0.706781882615661\n",
      "AUC: 0.6214402919758697\n",
      "\n",
      "Best Parameters for SGD SVM: {'alpha': 0.001, 'max_iter': 2000}\n",
      "Best Cross-Validation Score: 0.6343507003327082\n",
      "SGD SVM Training Time: 0.37 seconds\n",
      "SGD SVM Prediction Time: 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "sgd_svm = SGDClassifier(loss='hinge', random_state=39, max_iter=1000, tol=1e-3)\n",
    "\n",
    "# Cross-validation for SGDClassifier\n",
    "cv_sgd = cross_validate(sgd_svm, X_train, y_train, cv=5, scoring=scoring)\n",
    "print(\"\\nCross-Validation Results (SGDClassifier):\")\n",
    "print(\"Accuracy:\", np.mean(cv_sgd['test_accuracy']))\n",
    "print(\"Precision:\", np.mean(cv_sgd['test_precision']))\n",
    "print(\"Recall:\", np.mean(cv_sgd['test_recall']))\n",
    "print(\"F1 Score:\", np.mean(cv_sgd['test_f1']))\n",
    "print(\"Area under ROC:\", np.mean(cv_sgd['test_roc_auc']))\n",
    "\n",
    "# Cross-Validation on testing data\n",
    "start_time = time.time()\n",
    "sgd_svm.fit(X_train, y_train)\n",
    "train_time_sgd = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "y_predict_sgd = sgd_svm.predict(X_test)\n",
    "predict_time_sgd = time.time() - start_time\n",
    "\n",
    "print(\"\\nTest Set Evaluation (SGDClassifier):\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_predict_sgd))\n",
    "print(\"Precision:\", precision_score(y_test, y_predict_sgd))\n",
    "print(\"Recall:\", recall_score(y_test, y_predict_sgd))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_predict_sgd))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_predict_sgd))\n",
    "\n",
    "# Hyperparameter Tuning using GridSearchCV for SGDClassifier\n",
    "param_grid = {'alpha': [0.0001, 0.001, 0.01], 'max_iter': [1000, 2000]}\n",
    "grid_search = GridSearchCV(SGDClassifier(loss='hinge'), param_grid, cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nBest Parameters for SGD SVM:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Score:\", grid_search.best_score_)\n",
    "\n",
    "print(f\"SGD SVM Training Time: {train_time_sgd:.2f} seconds\")\n",
    "print(f\"SGD SVM Prediction Time: {predict_time_sgd:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing polynomial SVM \n",
    "In this, polynomial SVM is implemented using RBF kernel and a custom kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "# Function to calculate the metrics for a model with a certain degree\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    train_time = time.time() - start_time\n",
    "\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    predict_time = time.time() - start_time\n",
    "\n",
    "    # Calculation of metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1, auc, train_time, predict_time\n",
    "\n",
    "# Polynomial Kernel with degrees (2,3,4)\n",
    "for degree in [2, 3, 4]:\n",
    "    svm_polynomial = SVC(kernel='poly', degree=degree, random_state=39)\n",
    "    metrics = evaluate_model(svm_polynomial, X_train, X_test, y_train, y_test)\n",
    "    print(f\"\\nPolynomial SVM (degree={degree}) Accuracy:\", metrics[0])\n",
    "    results.append({\n",
    "        'Kernel': 'Polynomial',\n",
    "        'Degree': degree,\n",
    "        'Accuracy': metrics[0],\n",
    "        'Precision': metrics[1],\n",
    "        'Recall': metrics[2],\n",
    "        'F1 Score': metrics[3],\n",
    "        'AUC': metrics[4],\n",
    "        'Training Time (s)': metrics[5],\n",
    "        'Prediction Time (s)': metrics[6]\n",
    "    })\n",
    "\n",
    "# Tuning the C value for polynomial kernel and for each degree\n",
    "param_grid_poly = {'C': [0.1, 1, 10], 'degree': [2, 3, 4]}\n",
    "grid_search_poly = GridSearchCV(SVC(kernel='poly'), param_grid_poly, cv=3)\n",
    "grid_search_poly.fit(X_train, y_train)\n",
    "\n",
    "best_poly = grid_search_poly.best_estimator_\n",
    "metrics_best_poly = evaluate_model(best_poly, X_train, X_test, y_train, y_test)\n",
    "print(\"\\nBest Parameters for Polynomial SVM:\", grid_search_poly.best_params_)\n",
    "print(\"Best Polynomial SVM Accuracy:\", metrics_best_poly[0])\n",
    "\n",
    "results.append({\n",
    "    'Kernel': 'Polynomial',\n",
    "    'Degree': grid_search_poly.best_params_['degree'],\n",
    "    'Accuracy': metrics_best_poly[0],\n",
    "    'Precision': metrics_best_poly[1],\n",
    "    'Recall': metrics_best_poly[2],\n",
    "    'F1 Score': metrics_best_poly[3],\n",
    "    'AUC': metrics_best_poly[4],\n",
    "    'Training Time (s)': metrics_best_poly[5],\n",
    "    'Prediction Time (s)': metrics_best_poly[6]\n",
    "})\n",
    "\n",
    "# RBF Kernel with Gamma Tuning\n",
    "param_grid_rbf = {'C': [0.1, 1, 10], 'gamma': [0.1, 0.5, 1, 'scale']}\n",
    "grid_search_rbf = GridSearchCV(SVC(kernel='rbf'), param_grid_rbf, cv=3)\n",
    "grid_search_rbf.fit(X_train, y_train)\n",
    "\n",
    "best_rbf = grid_search_rbf.best_estimator_\n",
    "metrics_rbf = evaluate_model(best_rbf, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\nBest Parameters for RBF SVM:\", grid_search_rbf.best_params_)\n",
    "print(\"RBF SVM Accuracy:\", metrics_rbf[0])\n",
    "print(f\"Precision: {metrics_rbf[1]}, Recall: {metrics_rbf[2]}, F1 Score: {metrics_rbf[3]}, AUC: {metrics_rbf[4]}\")\n",
    "\n",
    "results.append({\n",
    "    'Kernel': 'RBF',\n",
    "    'Degree': 'N/A',\n",
    "    'Accuracy': metrics_rbf[0],\n",
    "    'Precision': metrics_rbf[1],\n",
    "    'Recall': metrics_rbf[2],\n",
    "    'F1 Score': metrics_rbf[3],\n",
    "    'AUC': metrics_rbf[4],\n",
    "    'Training Time (s)': metrics_rbf[5],\n",
    "    'Prediction Time (s)': metrics_rbf[6]\n",
    "})\n",
    "\n",
    "# Implementation of Custom Sigmoid Kernel\n",
    "def sigmoid_kernel(X, Y, a=1, b=1):\n",
    "    # a is the scaling term\n",
    "    # b is the offset term \n",
    "    # changing them can create new sigmoid kernel\n",
    "    return np.tanh(a * np.dot(X, Y.T) + b)\n",
    "\n",
    "# Tuning C for Custom Sigmoid Kernel\n",
    "param_grid_custom = {'C': [0.1, 1, 10]}\n",
    "grid_search_custom = GridSearchCV(SVC(kernel=sigmoid_kernel), param_grid_custom, cv=3)\n",
    "grid_search_custom.fit(X_train, y_train)\n",
    "\n",
    "best_custom = grid_search_custom.best_estimator_\n",
    "metrics_custom = evaluate_model(best_custom, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\nBest Parameters for Custom Sigmoid SVM:\", grid_search_custom.best_params_)\n",
    "print(\"Custom Sigmoid Kernel SVM Accuracy:\", metrics_custom[0])\n",
    "print(f\"Precision: {metrics_custom[1]}, Recall: {metrics_custom[2]}, F1 Score: {metrics_custom[3]}, AUC: {metrics_custom[4]}\")\n",
    "\n",
    "results.append({\n",
    "    'Kernel': 'Custom Sigmoid',\n",
    "    'Degree': 'N/A',\n",
    "    'Accuracy': metrics_custom[0],\n",
    "    'Precision': metrics_custom[1],\n",
    "    'Recall': metrics_custom[2],\n",
    "    'F1 Score': metrics_custom[3],\n",
    "    'AUC': metrics_custom[4],\n",
    "    'Training Time (s)': metrics_custom[5],\n",
    "    'Prediction Time (s)': metrics_custom[6]\n",
    "})\n",
    "\n",
    "# Comparisons\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nKernel Result Comparison:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "Using random search to tune the hyperparameters (C, degree) for polynomial kernel, (C, gamma) for RBF kernel, C for custom kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 9 is smaller than n_iter=10. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m random_search_poly\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      6\u001b[0m best_poly_random \u001b[38;5;241m=\u001b[39m random_search_poly\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m----> 7\u001b[0m metrics_best_poly_random \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m(best_poly_random, X_test, y_test)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBest Parameters for Polynomial SVM (Random Search):\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search_poly\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Polynomial SVM Accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics_best_poly_random[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Hyperparameter Tuning for Polynomial Kernel using RandomizedSearchCV\n",
    "param_dist_poly = {'C': [0.1, 1, 10], 'degree': [2, 3, 4]}\n",
    "random_search_poly = RandomizedSearchCV(SVC(kernel='poly'), param_distributions=param_dist_poly, n_iter=10, cv=3, random_state=42)\n",
    "random_search_poly.fit(X_train, y_train)\n",
    "\n",
    "best_poly_random = random_search_poly.best_estimator_\n",
    "metrics_best_poly_random = evaluate_model(best_poly_random, X_test, y_test)\n",
    "print(\"\\nBest Parameters for Polynomial SVM (Random Search):\", random_search_poly.best_params_)\n",
    "print(\"Best Polynomial SVM Accuracy:\", metrics_best_poly_random[0])\n",
    "\n",
    "# Hyperparameter Tuning for RBF Kernel using RandomizedSearchCV\n",
    "param_dist_rbf = {'C': [0.1, 1, 10], 'gamma': [0.1, 0.5, 1, 'scale']}\n",
    "random_search_rbf = RandomizedSearchCV(SVC(kernel='rbf'), param_distributions=param_dist_rbf, n_iter=10, cv=3, random_state=42)\n",
    "random_search_rbf.fit(X_train, y_train)\n",
    "\n",
    "best_rbf_random = random_search_rbf.best_estimator_\n",
    "metrics_rbf_random = evaluate_model(best_rbf_random, X_test, y_test)\n",
    "print(\"\\nBest Parameters for RBF SVM (Random Search):\", random_search_rbf.best_params_)\n",
    "print(\"RBF SVM Accuracy:\", metrics_rbf_random[0])\n",
    "\n",
    "# Hyperparameter Tuning for Custom Sigmoid Kernel using RandomizedSearchCV\n",
    "param_dist_custom = {'C': [0.1, 1, 10]}\n",
    "random_search_custom = RandomizedSearchCV(SVC(kernel=sigmoid_kernel), param_distributions=param_dist_custom, n_iter=10, cv=3, random_state=42)\n",
    "random_search_custom.fit(X_train, y_train)\n",
    "\n",
    "best_custom_random = random_search_custom.best_estimator_\n",
    "metrics_custom_random = evaluate_model(best_custom_random, X_test, y_test)\n",
    "print(\"\\nBest Parameters for Custom Sigmoid SVM (Random Search):\", random_search_custom.best_params_)\n",
    "print(\"Custom Sigmoid Kernel SVM Accuracy:\", metrics_custom_random[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter senstivity analysis\n",
    "Visulaizing the results of SVM performance using heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of hyperparameters for sensitivity analysis\n",
    "c_values = [0.1, 1, 10]\n",
    "gamma_values = [0.1, 0.5, 1, 'scale']\n",
    "results = []\n",
    "\n",
    "# Iterate over C and gamma values for RBF SVM\n",
    "for c in c_values:\n",
    "    for gamma in gamma_values:\n",
    "        svm = SVC(kernel='rbf', C=c, gamma=gamma)\n",
    "        cv_score = cross_val_score(svm, X_train, y_train, cv=5, scoring='accuracy')\n",
    "        results.append((c, gamma, np.mean(cv_score)))\n",
    "\n",
    "# Convert results to DataFrame for heatmap\n",
    "results_df = pd.DataFrame(results, columns=['C', 'Gamma', 'Accuracy'])\n",
    "pivot_table = results_df.pivot('C', 'Gamma', 'Accuracy')\n",
    "\n",
    "# Plotting heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(pivot_table, annot=True, cmap='viridis')\n",
    "plt.title('Hyperparameter Sensitivity Analysis for RBF Kernel')\n",
    "plt.xlabel('Gamma')\n",
    "plt.ylabel('C')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainability and Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize SHAP explainer on the best-performing model\n",
    "explainer = shap.KernelExplainer(best_rbf.predict, X_train[:100])  \n",
    "shap_values = explainer.shap_values(X_test[:100])\n",
    "\n",
    "# Plotting summaries\n",
    "shap.summary_plot(shap_values, X_test[:100], plot_type=\"bar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
